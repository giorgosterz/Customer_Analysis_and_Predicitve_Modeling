{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a sense of our data using Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by figuring where are our customers from and where is out problem geographically located"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Screenshots/Screenshot_3.png\" width='900' height='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the total of our customers are located in Germany, France and Spain with France having the majority of them and then Spain and Germany sharing the rest. This might be useful in the process where we see how many customers have exited from each country.\n",
    "\n",
    "Moving on, it would be helpful to smart to take a look at the Age distribution of our customers. That way we will get a much better understanding and idea of our customers' wants and needs but furthermore, we will be able to start guessing what is causing the churn problem. For example, if the majority of our customers is between 18 and 25 it would be wise to invest on our e-experience and technolgy facilitations our bank can offer. On the other hand, if our customers average an age of 50 then maybe we should focus on our retirement products and options offered. \n",
    "\n",
    "In any case, we can extract valuable information so let's see!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Screenshots/Screenshot_4.png\" width='900' height='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, more than half of our customers are between 30 and 40 years old. That gives us a good idea of what is the current state of our customer pool. But we do not have any clue yet if the customers who decide to leave the bank are also from this group or another one. We obvisouly need that information so we can start working on where the problem is really located and how we can tackle it. So let's see how are the customers distributed, this time considering whether they exited or not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Screenshots/Screenshot_5.png\" width='900' height='300'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph is eyeopening from many perspectives. Before we comment on the findings, we should clarify that the horizontal line at 20% has been put there as a reference for the total percentage of customers that left the bank. More specifically, from the 10,000 people in our dataset, 2000 have exited the bank. Now let's move on to the information we can draw from the picture. \n",
    "\n",
    "First of all, it is crystal clear that the churn problem is located to our customers between 45 and 60 years old. That is the timeframe which follows right after the age range where the majority of our customers fall in. Simply put, even though the biggest percentage of our customers is in their 30's, it is people after 40 years old who seem to be leaving the bank.\n",
    "\n",
    "Why is this happening? A possible explanation could be that the bank's employees did a similar analysis and saw that their customers are mainly in their 30's. Thus, they put all the weight and effort into creating products and services specifically targeted for them, neglecting the needs of people outside this age cap. As a result these people started looking for better oportunities in other financial institutes and when they did, they moved on with allocating their money to them. Of course, that is one of the million reasons that the churn problem is occuring, and a much deeper analysis should be conducted.\n",
    "\n",
    "Secondly, we can see that for the ages between 75 and 90 years old customers, almost 100% are staying with the bank. Even though that might have a logical explanation such that people of older age simple cannot be bothered with moving to another institution, the fact that we are having a 100% success rate makes us having second toughts. These kind of numbers are too good to be true. So the case might be that we actually have a very low number of observations in this age group in our dataset, which should be considered as outliers. This becomes more important in our model developing following our initial analysis where these outliers and should be treated seperately.\n",
    "\n",
    "This indicator takes us to our next graph. We want to acquire more specific-to-out-dataset information this time so we will plot the age of customers against the number of observation we have for each bin. This way we will also come to a conclusion regarding the older age group paradox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Screenshots/Screenshot_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we suspected, the observations in older age bins are significantly less compared to the rest of the bins. It would be wise to disregard everyone over 80 years old for our further analysis and future model developement.\n",
    "\n",
    "Now that we have exhausted everything regarding to age, it would be make sense to check the amount of money that our customers keep in their balances. Also, it would be better to combine this information with the actual number of customers who keep these amounts, since that would give us a more complete picture.\n",
    "\n",
    "<img src=\"Screenshots/Screenshot_7.png\" width='800' height='800' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the situation is different here is that we don't observe something that is \"screaming\" something at us, as we did in the previous graphs. We could continue investigating the small discrepanancies visible from bin to bin if we had a specific goal in our mind and we did care for example that we have 29% of 110K and 25% of 120K. However, in our case, these differneces conform with the average and there isn't a significant difference across the various balances in terms of probability of people leaving the bank. \n",
    "\n",
    "The bins that do actually present a discrepancy have a very low number of observations to be significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Designing A/B tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should bear in mind that these are not the full statistical AB tests because we will not check for statistical significance at this step. This step is useful because it helps us focus on things that actually matter and not waste time on variables that don't actually affect our end result. So this is a very quick and convenient visual approach which can give us very fast results. However, if we find something of interest we will go and investigate it further and follow the proper procedure for validating significance through chi-square testing. \n",
    "\n",
    "The classic and most commonly used example when AB test is an AB test for gender. So we will start by that.\n",
    "Basically what we'll be testing, is if we hold everything else equal and we take a male customer and a female customer which one of them is more likely to exit.\n",
    "\n",
    "<img src=\"Screenshots/Screenshot_1.png\" width='250' height='300'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see right away that irrespective of the number of female and male customers the percentage of male customers that left the bank is only 16 percent and that is less than the percentage of female customers that left the bank. So the conclusion that we can make from here is that all other things held equal, female customers are more likely to leave the bank than male customers.\n",
    "\n",
    "As we noted earlier the horizontal line at 20% has been put there as a reference for the total percentage of customers that left the bank. More specifically, from the 10,000 people in our dataset, 2000 have exited the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar manner, we can very quickly run these kind of tests for all of our variables and get a much better insight into our data. We will move on with the churn rate based on the geographic location.\n",
    "\n",
    "<img src=\"Screenshots/Screenshot_2.png\" width=\"300\" height=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It becomes obvious that people in Germany are exiting the bank at a rapid rate. Thirty two percent of customers left over the period of the observation. Contrary, France and Spain are below average. \n",
    "\n",
    "A reason for this exit rate in Germany might be the presence of a competitor in the country, another German bank for example, which have accomplished to take a large portion of our clients or the problem is internal and the products the bank offers are not suitable for the market. It is even possible that there is some sort of new legislation passed in the country that affected our customers and their taxes. In any case, something is going on and we can definetly dig deeper into this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more test that we could do is regarding whether the clients that are leaving are engaging into various activities with the bank or not. Let's check it out.\n",
    "\n",
    "<img src=\"Screenshots/Screenshot_9.png\" width='250' height='200'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result was sort of expected and backs our intuition that people who are actively using our bank are less likely to leave. Probably they have invested into the bank -or in one of the products- and they keep logging in and checking their balance, but they are in some way engaging into activity with the bank.\n",
    "\n",
    "We still have two categorical variables left to check, \"Number of Products\" and \"Has Credit Card\". Let's process with the former and see whether the number of products affect customers' decision to leave.\n",
    "\n",
    "<img src=\"Screenshots/Screenshot_10.png\" width='400' height='400'/>\n",
    "\n",
    "Here we can see right away a couple of things. \n",
    "\n",
    "First of all there are a few anomalies. We would expect that as the number of products increases the customer is more likely to stay with the bank. In banking, the term is called \"stickiness\" or \"the share of the wallet\" of the customer. The greater the \"share of the wallet\" the harder is for the customer to just abandon the bank. And that behavior is what we are oberving in the first two bins. People who have 2 products with the bank are much less likely to leave compared to the people who have 1. But then, when we move on to the next bins we are witnessing an anomaly. We see that when we get to 3 and 4 products, customers are leaving at a rapid rate. We have an 83% and 100% churn rate which does not apply for intuition whatsoever. Those are massive anomalies and we need to understand what we can do about them.\n",
    "\n",
    "The first thing that comes to mind when we have anomalies that great is there might be something wrong with the data, meaning that it might be an insignificant result, as we saw earlier with the age and exit rate. People over 80 years old seemed to have 100% churn rate but that was only because we had a very low number of observations in those bins. What if there's like only a hundrend people that had 4 products and they all just happened to leave.\n",
    "\n",
    "So in this case we need to check the actual number of people and that's what we are going to do.\n",
    "\n",
    "<img src=\"Screenshots/Screenshot_11.png\" width='400' height='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the first two categories have quite a lot of people but the rest categories have much fewer. Specifically, there are only around 350 in the last two categories combined. That can possibly be explained by the fact that the samples were selected randomly and it happened that the number of customers with 3 and 4 products is very low and they all decided to leave. \n",
    "\n",
    "In conclusion, we can say hat going from 1 product to 2 products it's harder for clients to leave, but for three or four products you would need to investigate further.\n",
    "\n",
    "There is still one categorical variable left to check and that would be the \"Has Credit Card\". So let's finish our quick visual tests with this one.\n",
    "\n",
    "<img src=\"Screenshots/Screenshot_8.png\" width='280' height='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, there isn't a much of a difference between someone who has and someone who has not a credit card. The difference is only one percent. Remember that this is not a full fledged statistical AB test. And if you do want to run the statistical A/B test then little differences like that require a very large sample size to be statistically significant. And in our case it's only 8000 people.\n",
    "\n",
    "If for some specific reason we wanted to examine that 1%, we take this further. But the point here is that this is not our best investment of time. We would much rather look at country or gender because their differences are massive and there we can actually have an impact and act upon the issue maybe by creating some business rules or by takeing some decisions to tackle that. But in this case, the 1% does not leave us a big margin of action and there's not much to fix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap everything up and before we continue with executing the chi-squared tests to prove -or not- the statistical significance of our findings, we should take a minute to validate our data. In order to do this we will use a random variable, meaning that we will pick, or in our case create, a variable that has zero predictive power over the decision of customers leaving the bank. Specifically, we will choose the last digit of the customers' ID.\n",
    "\n",
    "Validation, in this context, means that there is no skew in the data generation process. In other words, it would be very unlikely that a randomly generated last digit of a variable has more frequency of some digit over others if the data was perfectly generated.\n",
    "\n",
    "Of course, there is no guarantee that our data generation process is perfect if it passes this validation step, but thinking the other way round, we should investigate if it fails this test.\n",
    "\n",
    "So let's graph our customers' ID last digit. We should expect everything to be uniformly distributed.\n",
    "\n",
    "<img src=\"Screenshots/Screenshot_12.png\" width='700' height='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we forsaw, the data is uniformly distributed, even though there is a minor fluctuation around the average (20%) that is not significant. Now we can see that our sample is valid because if it wasn't or if we did see some some skewness then maybe we would question our sampling technique and seek for a new sample with a different data generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared test validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have drawn some great insights from our data by designing these quick and convinient tests. We know for example that age does have a significant impact on the decision of someone to leave. Also it seems to be an assotiation between the gender and the clients' actions too. However, as we mentioned, these were not the hard statistical tests.\n",
    "\n",
    "But how do we get confident with these tests and how can we be sure that what we're reporting is actually the result and that we can use this as insights to drive business decisions and we can communicate this to managers and executives? That's where the chi squared test comes in.\n",
    "\n",
    "What the chi square tests will tell us is whether the former results are statistically significant. We did observe some differences in our sample. Were these just random differences? For example, has it happened by chance that there is a difference between female and male or is this happens consistently and we can confidently say that we will observe a similar discrepancy in the whole populaition of the bank? That's what the chi-squared test will tell us. More formally, the chi-squared test can be used to determine how well a theoretical distribution fits an observed empirical distribution.\n",
    "\n",
    "For more information on chi-squared distribution and chi-squared tests feel free to visit [Wikipedia's page](https://en.wikipedia.org/wiki/Chi-squared_test) as the details of how we are going to calculate the result is outside the scope of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conduct our tests we will use an online tool that is very quick and can help us do these tests ad hoc. Keep in mind that with chi squared we canâ€™t use percentages we need to use the actual values. We will check the statistical significance of our results through this [site](https://www.evanmiller.org/ab-testing/chi-squared.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"Screenshots/Screenshot_13.png\" style=\"width: 600px;\"/> </td>\n",
    "        <td> <img src=\"Screenshots/Screenshot_14.png\" style=\"width: 600px;\"/> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> <img src=\"Screenshots/Screenshot_15.png\" style=\"width: 600px;\"/> </td>\n",
    "        <td> <img src=\"Screenshots/Screenshot_16.png\" style=\"width: 600px;\"/> </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As \"# successes\" we set the number of people who **Exited** the bank and as \"# trials\" the total number in that category.\n",
    "\n",
    "- Top left : Sample 1 is the Female customers and since it came out as more successful, *Female customers have a higher exit rate and it is statistically significant*.\n",
    "- Top right : Sample 1 is the Not Active customers and since it came out as more successful, *Not Active customers have a higher exit rate and it is statistically significant*.\n",
    "- Bottom left: There is no significant difference between the sample of customers who have a credit card and customers who don't have a credit card.\n",
    "- Bottom right: Since we have the problem with the nuber of observations for \"Number of Products\" we conduct our chi-square test **only bewteen 1 product and 2 products**. Sample 1 is the customers who own one product with the bank and since it came out as more successful, *customers with only one product have a higher exit rate and it is statistically significant*.\n",
    "\n",
    "What is left, is to use a chi-squared test validation regarding the location, the country that our customers are in. But here, we have more than two categories for our variable, so the previous layout won't work since it had the capacity for only two categories (two samples). That is why now we will use a different online tool which can be found in this [site](http://www.vassarstats.net/newcs.html)\n",
    "\n",
    "<img src=\"Screenshots/Screenshot_17.png\" width ='450'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again there is a statistical significance, meaning that when we go to the overall population rather than looking at this secific sample, we will also see a similar effect and people who reside in Germany will be more likely to leave the bank than people who reside in Spain or France.\n",
    "\n",
    "Now that we have conducted a formal statistical analysis we are confident about our results' signifinance. A noteable observation is that the results were a perfect match with the insights we acquired at the first step, when we just had the visual representations of these A/B tests. That does not mean that we should rely just on them, but it does seem like a good way to help us focus on the variables that actually have an impact on our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have concluded our first analysis and we got a good grasp of our data, our next goal is to develop a model which will be able to predict whether a customer is in the \"danger zone\" of leaving us. So our goal is to estimate the probability of a customer leaving the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our approach:\n",
    "\n",
    "In order to attack this problem we want to compare our well-known classifiers, keep the one that performs the best, tune it and use it for predictions. But instead of just fitting all of the available classifiers we will use the SVM and its ability to switch between the linear and non-linear kernel through Grid Search to understand whether our data are related linearly or not. That will allow us to exclude some algorithms and use the appropriate kernels for others. As a result we will save on computational power and focus on efficiency from the very first step.\n",
    "\n",
    "Applying this \"trick\" returns as a best performing kernel the \"rbf\", meaning our data exhibit mostly a non linear relationship. Hence, we can immediatly exclude Logistic Regression from our classifiers and use \"rbf\" and \"gbtree\" for Support Vector machine and XGB accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring performance:\n",
    "\n",
    "When it comes to classification problems, it is a common tactic to rely on \"accuracy\" as a metric to choose an algorithm. But in some cases, included this one, this can lead to making the wrong decision since we may fall into the \"accuracy paradox\" trap. According to the \"accuracy paradox\", when our target value is consisted of highly imbalanced classes, we may completely ditch our model and start classifying everything to the superior class and still get a better accuracy than actually using a well-trained model. That is depicted in the picture below.\n",
    "\n",
    "<img src=\"Screenshots/accuracy_paradox.png\" width='600' height='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a countplot for our targer variable \"Exited\" we can see that our problems falls under the \"imbalances targer values\" category. Hence, proceeding with plain accuracy as a metric will not be a suitable tactic.\n",
    "\n",
    "<img src=\"Screenshots/Exited_countplot.png\" width='400' height='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### An alternative\n",
    "\n",
    "Instead, we can use ROC curves. ROC curves are able to handle this imbalance and take it into consideration when they calculate the results. But using only one run of our data to form a ROC curve is also a tactic that can be misleading. The picture below summarizes this perfectly. \n",
    "\n",
    "<img src=\"Screenshots/why_cv_roc.png\" width='400' height='400'/>\n",
    "\n",
    "Different runs will produce different ROC curves, so by counting on the result after only one run does not look like a smart strategy. To counter this problem and shield ourselves, we will instead do the following: we will use K-fold cross-validation and produce a ROC curve for each one of the folds. Then we will take the \"mean curve\" for each one of our models, which will be the equivalent to the blue ROC curve in the picture above. That will minimize the variance of our validation approach.\n",
    "\n",
    "After picking our classifiers and applying the method we described, we acquire the following results.\n",
    "\n",
    "<img src=\"Screenshots/roc_curves.png\" width='600' height='400'/>\n",
    "\n",
    "The metrics table for our classifiers can also be examined:\n",
    "\n",
    "<img src=\"Screenshots/metrics_table_cls.png\" width='700' height='400'/>\n",
    "\n",
    "It looks like XGBClassifier marginally outperforms the rest of the competitive algorithms, so this is the one that we choose to continue with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning the model:\n",
    "\n",
    "There is a huge number of parameters someone can tune in the [XGB model](https://xgboost.readthedocs.io/en/latest/parameter.html). For the shake of computational resources and  efficiency we will only tune the learning rate 'eta', loss reduction 'gamma' and maximun depth of the trees 'max_depth'. \n",
    "\n",
    "Applying grid search returns the following table of optimal parameters which achieve the best accuracy:\n",
    "\n",
    "<img src=\"Screenshots/best_params.png\" width='250' height='400'/>\n",
    "\n",
    "According to these results, we build a classifier which will handle our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making the predictions\n",
    "\n",
    "We create our final classifier, pass the above parameters and make our predictions. To get a good visual and quantitative picture of our classifier we will plot the confusion matrix, the ROC curve and a table with metrics which we will use later to compare the XGB classifier with an artificial neural network.\n",
    "\n",
    "The confusion matrix:\n",
    "<img src=\"Screenshots/cm.png\" width='650' height='400'/>\n",
    "The ROC Curve:\n",
    "<img src=\"Screenshots/xgb_roc_curve.png\" width='650' height='400'/>\n",
    "The metrics table:\n",
    "<img src=\"Screenshots/xgb_test_metrics.png\" width='600' height='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with an Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we said in the preview, we will create a deep learning model which we will then use as a classifier for our Churn problem. Even though we already have a well trained and effective algorithm it would be nice to spice things up by comparing it to a simple model based on neurons. \n",
    "\n",
    "Deep learning modeling is a relatively new field and whether it is (or will be in the immediate future) better in terms of performance compared to the traditional machine learning, is a subject which has led to many heated debates. So we will use this project as an opportunity to draw some cocnlusions for ourselves.\n",
    "\n",
    "The ANN we wil be using in this problem can be seen in the picture below, with the inputs and the corresponding output. The depth and the number of neurons of the ANN depicted differ to the one that we will create for practical reasons.\n",
    "<img src=\"Screenshots/Neural_Network_Churn.png\" width='400' height='400'/>\n",
    "\n",
    "And the exact architecture of our ANN is summarized below:\n",
    "\n",
    "<img src=\"Screenshots/ANN_summary.png\" width='500' height='400'/>\n",
    "\n",
    "We will not perform any kind of tuning to our neural network, but anyone who will use the code can try playing around with the parameters and hyperparameters, the depth of the ANN and the number of neurons in each layer. \n",
    "\n",
    "Now let's train our ANN, make the predictions and compare the results with the ones coming from the XGB classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics table for the ANN:\n",
    "\n",
    "<img src=\"Screenshots/ANN_metrics.png\" width='700' height='400'/>\n",
    "\n",
    "We can see that the untuned ANN achieved a very similar performance to the tuned XGB classifier.\n",
    "\n",
    "Let's also visualize this comparison with their confusion matrices.\n",
    "\n",
    ">XGB confusion matrix:\n",
    "\n",
    "<img src=\"Screenshots/xgb_cm.png\" width='250' height='400'/>\n",
    "\n",
    ">ANN confusion matrix:\n",
    "\n",
    "<img src=\"Screenshots/ann_cm.png\" width='227' height='400'/>\n",
    "\n",
    "\n",
    "There we have it! Our ANN proved to be a worthy opponent, even though we did not perform any kind of tuning. If we provided sufficient tuning there is a chance that the neural network would perform better than the XGB classifier but most probably it would not surpass it to an extreme amount. There is definitely not a \"clear winner\" etween the two. Besides, following a common saying in data science \"There is no free lunch\". So at every problem we should experiment with all kind of different solutions and keep the one that performs the best in each particular case!\n",
    "\n",
    "I hope you enjoyed this project!\n",
    "\n",
    "**Thank you!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
